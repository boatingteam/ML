{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Random Forests\n",
    "\n",
    "We will again look at predicting the quality of wine (either good or bad) based on various predictors. A random forest model creates many decision trees, where each decision tree is constructed using a subset of all features. Then to make a prediction, a random forest model asks each tree what its prediction is. And whatever prediction is made by the most trees, is the final prediction made by the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "wine = pd.read_csv('heart_disease_data.csv',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>140</td>\n",
       "      <td>311</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>138</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  num\n",
       "0   62    1   4       160   254    1        1      108      1      3.0    1\n",
       "1   46    1   4       140   311    0        0      120      1      1.8    1\n",
       "2   39    0   3       138   220    0        0      152      0      0.0    0\n",
       "3   56    1   1       120   193    0        2      162      0      1.9    0\n",
       "4   43    0   2       120   201    0        0      165      0      0.0    0"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(561, 11)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 561 entries, 0 to 560\n",
      "Data columns (total 11 columns):\n",
      "age         561 non-null int64\n",
      "sex         561 non-null int64\n",
      "cp          561 non-null int64\n",
      "trestbps    561 non-null int64\n",
      "chol        561 non-null int64\n",
      "fbs         561 non-null int64\n",
      "restecg     561 non-null int64\n",
      "thalach     561 non-null int64\n",
      "exang       561 non-null int64\n",
      "oldpeak     561 non-null float64\n",
      "num         561 non-null int64\n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 48.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the numpy arrays\n",
    "x = np.array(wine.iloc[:,0:10])\n",
    "y = np.array(wine[\"num\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training set and test set. I'm putting 33% into test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Fit Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\52617\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the random forest classifier and fit it\n",
    "# to the training data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the random forest model to make predictions of wine quality\n",
    "# on the test set\n",
    "y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77, 21],\n",
       "       [25, 63]], dtype=int64)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And then evaluate our model performance on that test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7526881720430108"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy => the proportion of wines that were correctly classified\n",
    "# i.e. it is the true positives + true negatives divided by all wines\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision => out of all those wines that were predicted GOOD, what proportion truely were?\n",
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test,y_test_pred,pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7159090909090909"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall => Out of all those wines that are GOOD, what proportion were also predicted as GOOD\n",
    "from sklearn.metrics import recall_score\n",
    "recall_score(y_test,y_test_pred,pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Importance\n",
    "\n",
    "An interesting and useful feature of random forests is that based on the generated trees, we can calculate the importance of the different variables! See the sklearn documentation for the details. But to find the variable importances, use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13989814 0.04397072 0.12994805 0.10957627 0.12171914 0.02443111\n",
      " 0.02773919 0.15292884 0.07361018 0.17617836]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
       "       'exang', 'oldpeak', 'num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And these correlate to the predictors:\n",
    "wine.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My model is bad! How do I make it better???? (Model Parameters)\n",
    "\n",
    "Lots of models allow you to set parameters that change the behaviour of those models. Trying out different parameters could lead to a better model for your data. Use the sklearn documentation to figure out what parameters a model takes. Here I'll use random forests as an example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the random forest documentation at:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "# On that page, you'll find various possible parameters for the random forest model.\n",
    "# Let's try a random forest model with 20 decision trees, and a max depth of 5 and no more\n",
    "# than 7 features per tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=5, max_features=10, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestClassifier(n_estimators = 50, max_depth = 5, max_features = 10)\n",
    "model2.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77 21]\n",
      " [25 63]]\n",
      "Accuracy:  {} 0.7849462365591398\n",
      "Precision: {} 0.7727272727272727\n",
      "Recall:    {} 0.7727272727272727\n"
     ]
    }
   ],
   "source": [
    "# let's evaluate that model:\n",
    "y_test_pred2 = model2.predict(x_test)\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print(\"Accuracy:  {}\",accuracy_score(y_test,y_test_pred2))\n",
    "print(\"Precision: {}\",precision_score(y_test,y_test_pred2,pos_label=1))\n",
    "print(\"Recall:    {}\",recall_score(y_test,y_test_pred2,pos_label=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Grid Search Through Parameters\n",
    "\n",
    "You can use Grid Search to try lots of different parameter combinations. Here is the code to do that, with random forests as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'max_depth': [3, 5, 50, 100, 150, 200],\n",
       "                         'max_features': ['auto', 10],\n",
       "                         'n_estimators': [50, 100, 150, 200, 250, 300]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a dictionary mapping parameter names to lists of values to try!\n",
    "param_grid = {'n_estimators':[50,100,150,200,250,300],\n",
    "              'max_depth': [3,5,50,100,150,200],\n",
    "              'max_features': [\"auto\",10]}\n",
    "\n",
    "# The above means that we try 3*3*2 = 18 random forest models! The first one has\n",
    "# 50 trees with max_depth of 3 and automatically determined number of features\n",
    "# per tree.\n",
    "\n",
    "# Then to fit the model, we do this.\n",
    "# 1. Create random forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# 2. Create a GridSearchCV object and tell it about your\n",
    "#    random forest model and paramater grid. cv = 3 means\n",
    "#    you want to use 3-fold cross validation.\n",
    "rf_cv= GridSearchCV(rf,param_grid,cv=3)\n",
    "\n",
    "# 3. Now fit the model to the training data\n",
    "rf_cv.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "{'max_depth': 5, 'max_features': 'auto', 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Now to find the best found score and parameters do:\n",
    "print(rf_cv.best_score_)\n",
    "print(rf_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so it seems from our 18 models, the best random forest model had\n",
    "# 200 trees, automatically determined number of features and a\n",
    "# max_depth of 1000. We can now just create that model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = RandomForestClassifier(n_estimators = 200, max_depth = 1000, max_features=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_final = rf_cv.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78, 20],\n",
       "       [18, 70]], dtype=int64)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_test_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956989247311828"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,y_test_pred_final,pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954545454545454"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test,y_test_pred_final,pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
